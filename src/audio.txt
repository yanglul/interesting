
extern crate ffmpeg_next as ffmpeg;


 
use std::{collections::HashMap, io::Write};
use std::env;
 

use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};
use ffmpeg::{
    codec::{self}, decoder::{self, new}, encoder, format, frame::{self, Audio, Video}, log, media, picture, Dictionary, Packet, Rational,
};

use ffmpeg_next::software::scaling::{context::Context as ScaleContext, flag::Flags};
use ffmpeg_next::format::Sample as FFmpegSample;
use ffmpeg_next::format::sample::Type as SampleType;
use ffmpeg_next:: codec::  Context as CodecContext;
use ffmpeg_next::util::format::pixel::Pixel;


use sdl2::video::{Window, WindowContext};
use sdl2::pixels::Color;
use std::time::{Instant};

extern crate cpal;
use ffmpeg_next::software::resampling::{context::Context as ResamplingContext};
use cpal::{SampleFormat};

use ringbuf::{traits::*, HeapRb};
const RING_BUFFER_SIZE: usize = 44100 * 2 * 5; // 5秒的44.1kHz立体声缓冲
 
trait SampleFormatConversion {
    fn as_ffmpeg_sample(&self) -> FFmpegSample;
}

impl SampleFormatConversion for SampleFormat {
    fn as_ffmpeg_sample(&self) -> FFmpegSample {
        match self {
            Self::I16 => FFmpegSample::I16(SampleType::Packed),
            Self::U16 => {
                panic!("ffmpeg resampler doesn't support u16")
            }, 
            Self::F32 => FFmpegSample::F32(SampleType::Packed),
            _  =>FFmpegSample::F32(SampleType::Packed),

        }
    }
}
 

fn init_cpal() -> (cpal::Device, cpal::SupportedStreamConfig) {
    let device = cpal::default_host()
        .default_output_device()
        .expect("no output device available");

    // Create an output stream for the audio so we can play it
    // NOTE: If system doesn't support the file's sample rate, the program will panic when we try to play,
    //       so we'll need to resample the audio to a supported config
    let supported_config_range = device.supported_output_configs()
        .expect("error querying audio output configs")
        .next()
        .expect("no supported audio config found");

    // Pick the best (highest) sample rate
    (device, supported_config_range.with_max_sample_rate())
}

// Interpret the audio frame's data as packed (alternating channels, 12121212, as opposed to planar 11112222)
pub fn packed<T: frame::audio::Sample>(frame: &frame::Audio) -> &[T] {
    if !frame.is_packed() {
        panic!("data is not packed");
    }

    if !<T as frame::audio::Sample>::is_valid(frame.format(), frame.channels()) {
        panic!("unsupported type");
    }

    unsafe { std::slice::from_raw_parts((*frame.as_ptr()).data[0] as *const T, frame.samples() * frame.channels() as usize) }
}
fn err_fn(err: cpal::StreamError) {
    eprintln!("an error occurred on stream: {}", err);
}

pub fn run() {
    let input_file = "D:\\workspace\\Rwork\\testffmpeg\\双烤.mp4";
   
    ffmpeg::init().unwrap();
    log::set_level(log::Level::Info);

    let mut ictx = format::input(&input_file).unwrap();
    // let mut octx = format::output(&output_file).unwrap();

    format::context::input::dump(&ictx, 0, Some(&input_file));
    // 查找视频流
    let video_stream_index = ictx
        .streams()
        .best(media::Type::Video)
        .map(|stream| stream.index()).expect("视频索引获取失败");
    

    let video_stream = ictx.stream(video_stream_index).unwrap();
    let codec_ctx = CodecContext::from_parameters(video_stream.parameters()).unwrap();
 

    // 打开解码器
    let mut video_decoder =  codec_ctx.decoder().video().unwrap();

    // 查找音频流
    let audio_stream_index = ictx
        .streams()
        .best(media::Type::Audio)
        .map(|stream| stream.index()).expect("音频索引获取失败");


    let audio_stream = ictx.stream(audio_stream_index).unwrap();
    let audio_codec_ctx = CodecContext::from_parameters(audio_stream.parameters()).unwrap();
    let mut audio_decoder = audio_codec_ctx.decoder().audio().unwrap();

     

    #[cfg(any(
        not(any(
            target_os = "linux",
            target_os = "dragonfly",
            target_os = "freebsd",
            target_os = "netbsd"
        )),
        not(feature = "jack")
    ))]
    let host = cpal::default_host();    
    let output_device = host.default_output_device();



    let (device, stream_config) = init_cpal();
    println!("audio_decoder.format(){:?}",audio_decoder.format());
    println!("stream_config.sample_format(){:?}",stream_config.sample_format());
    // Set up a resampler for the audio
    let mut resampler = ResamplingContext::get(
        audio_decoder.format(),
        audio_decoder.channel_layout(),
        audio_decoder.rate(),
        
        stream_config.sample_format().as_ffmpeg_sample(),
        audio_decoder.channel_layout(),
        stream_config.sample_rate().0
    ).unwrap();

    // A buffer to hold audio samples
    let buf = HeapRb::<f32>::new(8192);
    let (mut producer, mut consumer) = buf.split();
    let output_data_fn = move |data: &mut [f32], _: &cpal::OutputCallbackInfo| {
        let mut input_fell_behind = false;
        for sample in data {
            *sample = match consumer.try_pop() {
                Some(s) => s,
                None => {
                    input_fell_behind = true;
                    0.0
                }
            };
        }
        if input_fell_behind {
            eprintln!("input stream fell behind: try increasing latency");
        }
    }; 

      
    // Set up the audio output stream
    let audio_stream = match stream_config.sample_format() {
        SampleFormat::F32 => device.build_output_stream(&stream_config.into(),output_data_fn,  err_fn,None),
        SampleFormat::I16 => panic!("i16 output format unimplemented"),
        SampleFormat::U16 => panic!("u16 output format unimplemented"),
        _=> device.build_output_stream(&stream_config.into(),output_data_fn,  err_fn,None),
    }.unwrap();

   
     //加载视频信息
    std::thread::spawn(move || {


    });


    // 播放音视频
    audio_stream.play().unwrap();
    
}

 